{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNaVQGQ9tQRr"
   },
   "source": [
    "# **Multiclass Classification using Keras and TensorFlow on Food-101 Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oNJr8de7yp3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 10:34:22.431901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-08 10:34:22.732866: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-08-08 10:34:24.069755: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-08-08 10:34:24.069903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-08-08 10:34:24.069917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S, EfficientNetV2L\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get update\n",
    "# !apt-get install ffmpeg libsm6 libxext6  -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TEC_CRt_c_Z"
   },
   "source": [
    "### **Download the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JOZZbCDoP-Hy"
   },
   "outputs": [],
   "source": [
    "# # Check if GPU is enabled\n",
    "# print(tf.__version__)\n",
    "# print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i4hckYW2yp3c"
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/input/food-101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f88XvEBTQBS9"
   },
   "outputs": [],
   "source": [
    "# # Helper function to download data and extract\n",
    "# def get_data_extract():\n",
    "#   if \"food-101\" in os.listdir():\n",
    "#     print(\"Dataset already exists\")\n",
    "#   else:\n",
    "#     print(\"Downloading the data...\")\n",
    "#     !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
    "#     print(\"Dataset downloaded!\")\n",
    "#     print(\"Extracting data..\")\n",
    "#     !tar xzvf food-101.tar.gz\n",
    "#     print(\"Extraction done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7kY0v23QJGO",
    "outputId": "c4afcace-bc05-4589-e314-c70f96806937"
   },
   "outputs": [],
   "source": [
    "# Download data and extract it to folder\n",
    "# Uncomment this below line if you are on Colab\n",
    "# get_data_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIgareCETmct"
   },
   "source": [
    "### **Split the image data into train and test using train.txt and test.txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xB0XMUX_5KMQ"
   },
   "outputs": [],
   "source": [
    "# # Helper method to split dataset into train and test folders\n",
    "# def prepare_data(filepath, src,dest):\n",
    "#   classes_images = defaultdict(list)\n",
    "#   with open(filepath, 'r') as txt:\n",
    "#       paths = [read.strip() for read in txt.readlines()]\n",
    "#       for p in paths:\n",
    "#         food = p.split('/')\n",
    "#         classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "#   for food in classes_images.keys():\n",
    "#     print(\"\\nCopying images into \",food)\n",
    "#     if not os.path.exists(os.path.join(dest,food)):\n",
    "#       os.makedirs(os.path.join(dest,food))\n",
    "#     for i in classes_images[food]:\n",
    "#       copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "#   print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJyt1aH-DDfh",
    "outputId": "7f44b6c9-764a-47be-f53a-080c5ac173e1"
   },
   "outputs": [],
   "source": [
    "# %cd food-101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSgcYcqy5KUd",
    "outputId": "2d3f475d-5dd7-42c6-95fe-7a4fd2fd3653"
   },
   "outputs": [],
   "source": [
    "# prepare_data('/content/food-101/meta/train.txt', '/content/food-101/images', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JI65wZgT5Kb-",
    "outputId": "d6164673-667f-4fad-a4f6-69bdadfdd1bb"
   },
   "outputs": [],
   "source": [
    "# prepare_data('/content/food-101/meta/test.txt', '/content/food-101/images', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xccc8PJP5K1G",
    "outputId": "2d5f8b05-daaf-4e0f-c974-decec71737d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in train folder\n",
      "find: ‘train’: No such file or directory\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# # Check how many files are in the train folder\n",
    "# print(\"Total number of samples in train folder\")\n",
    "# !find train -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iz3fjQw25K3-",
    "outputId": "21e1b0ac-72b1-407b-e69e-55239a249ac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in test folder\n",
      "25250\n"
     ]
    }
   ],
   "source": [
    "# # Check how many files are in the test folder\n",
    "# print(\"Total number of samples in test folder\")\n",
    "# !find test -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5rLWIHpUGWf"
   },
   "source": [
    "### **Create a subset of data with few classes(3) - train_mini and test_mini for experimenting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tYyJGTJ6J9CP"
   },
   "outputs": [],
   "source": [
    "# # Helper method to create train_mini and test_mini data samples\n",
    "# def dataset_mini(food_list, src, dest):\n",
    "#   if os.path.exists(dest):\n",
    "#     rmtree(dest) # removing dataset_mini(if it already exists) folders so that we will have only the classes that we want\n",
    "#   os.makedirs(dest)\n",
    "#   for food_item in food_list :\n",
    "#     print(\"Copying images into\",food_item)\n",
    "#     copytree(os.path.join(src,food_item), os.path.join(dest,food_item))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9YAscZLV5LFK"
   },
   "outputs": [],
   "source": [
    "# # picking 3 food items and generating separate data folders for the same\n",
    "# food_list = ['apple_pie','pizza','omelette']\n",
    "# src_train = 'train'\n",
    "# dest_train = 'train_mini'\n",
    "# src_test = 'test'\n",
    "# dest_test = 'test_mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvlXbJ3NoPzy",
    "outputId": "164b2b38-9b6a-46aa-bea3-fa9cc79d039c"
   },
   "outputs": [],
   "source": [
    "# print(\"Creating train data folder with new classes\")\n",
    "# dataset_mini(food_list, src_train, dest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7mWJCev5LI8",
    "outputId": "0c034278-b1d7-4586-8e8b-cb5199e137ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in train folder\n",
      "2250\n"
     ]
    }
   ],
   "source": [
    "# print(\"Total number of samples in train folder\")\n",
    "\n",
    "# !find train_mini -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4aeURey5LLy",
    "outputId": "70761a91-6917-4c6e-d6c0-f6264789904a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test data folder with new classes\n",
      "Copying images into apple_pie\n",
      "Copying images into pizza\n",
      "Copying images into omelette\n"
     ]
    }
   ],
   "source": [
    "# print(\"Creating test data folder with new classes\")\n",
    "# dataset_mini(food_list, src_test, dest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBLq_gYD5LOm",
    "outputId": "3fdb15d0-60b6-429b-873a-3b51827839e5"
   },
   "outputs": [],
   "source": [
    "# print(\"Total number of samples in test folder\")\n",
    "# !find test_mini -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uBYnTC8I4mw"
   },
   "source": [
    "### **Data Augmentation and Acc/Loss Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "%cd .. # Run it two times to go to workspace dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HC3eXlRJHMI7",
    "outputId": "5c45e504-956c-4f38-d79c-460138afdf3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75750 images belonging to 101 classes.\n",
      "Found 25250 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "n_classes = 101\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = 'persistent/food-101/train'\n",
    "validation_data_dir = 'persistent/food-101/test'\n",
    "# train_data_dir = '/Users/dim__gag/python/food-101/data_mini/train_mini'\n",
    "# validation_data_dir = '/Users/dim__gag/python/food-101/data_mini/test_mini'\n",
    "\n",
    "nb_train_samples = 2250 #75750\n",
    "nb_validation_samples = 750 #25250\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "EpyszTY3iyyI"
   },
   "outputs": [],
   "source": [
    "# Plot Accuracy and Loss of the model\n",
    "def plot_accuracy(history,title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
    "    plt.show()\n",
    "def plot_loss(history,title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_Acc_and_Loss(history,title):\n",
    "    # plot model accuracy\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
    "    # plot model loss\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hArz5ffBjtwm"
   },
   "source": [
    "## **EfficientNetV2S & SAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zxc063O9powb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 10:38:02.736083: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-08-08 10:38:02.736162: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-08 10:38:02.736600: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyterlab-gpu-5-gwdmm): /proc/driver/nvidia/version does not exist\n",
      "2022-08-08 10:38:02.737505: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-l_notop.h5\n",
      "473176280/473176280 [==============================] - 7s 0us/step\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S, EfficientNetV2L\n",
    "# base_EffNet = EfficientNetV2S(include_top=False, weights='imagenet')\n",
    "base_EffNet = EfficientNetV2L(include_top=False, weights='imagenet')\n",
    "\n",
    "# base_EffNet = EfficientNetV2S(\n",
    "#     include_top=False,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_tensor=None,\n",
    "#     input_shape=None,\n",
    "#     pooling=None,\n",
    "#     classes=1000,\n",
    "#     classifier_activation=\"softmax\",\n",
    "#     include_preprocessing=True)\n",
    "\n",
    "\n",
    "base_EffNet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kzsXXkvyvV9j"
   },
   "outputs": [],
   "source": [
    "# base_EffNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PPkNXdtSvV7O"
   },
   "outputs": [],
   "source": [
    "# Fine tune the model\n",
    "x = base_EffNet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(3, kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "EffNet = Model(inputs=base_EffNet.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XDpUw9m8vV4s"
   },
   "outputs": [],
   "source": [
    "# EffNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "L1NcXkVUFSe5"
   },
   "outputs": [],
   "source": [
    "# <-------------------------------------------------------------------------------------------------------------->\n",
    "class SAMModel(tf.keras.Model):\n",
    "    def __init__(self, model, rho=0.05):\n",
    "        \"\"\"\n",
    "        p, q = 2 for optimal results as suggested in the paper\n",
    "        (Section 2)\n",
    "        \"\"\"\n",
    "        super(SAMModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.rho = rho\n",
    "\n",
    "    def train_step(self, data):\n",
    "        (images, labels) = data\n",
    "        e_ws = []\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.model(images)\n",
    "            loss = self.compiled_loss(labels, predictions)\n",
    "        trainable_params = self.model.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_params)\n",
    "        grad_norm = self._grad_norm(gradients)\n",
    "        scale = self.rho / (grad_norm + 1e-12)\n",
    "\n",
    "        for (grad, param) in zip(gradients, trainable_params):\n",
    "            e_w = grad * scale\n",
    "            param.assign_add(e_w)\n",
    "            e_ws.append(e_w)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.model(images)\n",
    "            loss = self.compiled_loss(labels, predictions)    \n",
    "        \n",
    "        sam_gradients = tape.gradient(loss, trainable_params)\n",
    "        for (param, e_w) in zip(trainable_params, e_ws):\n",
    "            param.assign_sub(e_w)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(sam_gradients, trainable_params))\n",
    "        \n",
    "        self.compiled_metrics.update_state(labels, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        (images, labels) = data\n",
    "        predictions = self.model(images, training=False)\n",
    "        loss = self.compiled_loss(labels, predictions)\n",
    "        self.compiled_metrics.update_state(labels, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def _grad_norm(self, gradients):\n",
    "        norm = tf.norm(\n",
    "            tf.stack([\n",
    "                tf.norm(grad) for grad in gradients if grad is not None\n",
    "            ])\n",
    "        )\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "h65CJmO43gRI"
   },
   "outputs": [],
   "source": [
    "model = SAMModel(EffNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PDVyHLDuFXDK"
   },
   "outputs": [],
   "source": [
    "# GET THE SAM MODEL\n",
    "model.trainable = True # Unfreeze the model\n",
    "model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# checkpointer = ModelCheckpoint(filepath='EfficientSAM.hdf5', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger('EfficientSAM.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKC6AeOn0IB3",
    "outputId": "f5095541-c5e0-449d-ecf0-97ce75548a1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_20753/3506946629.py\", line 3, in <cell line: 3>\n      history = model.fit(train_generator, steps_per_epoch = nb_train_samples // batch_size, validation_data=validation_generator, validation_steps=nb_validation_samples // batch_size, epochs=400, verbose=1, callbacks=[csv_logger])\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/tmp/ipykernel_20753/190348602.py\", line 17, in train_step\n      loss = self.compiled_loss(labels, predictions)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 1990, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/backend.py\", line 5534, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[16,3] labels_size=[16,101]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_109592]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m K\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnb_train_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_validation_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_20753/3506946629.py\", line 3, in <cell line: 3>\n      history = model.fit(train_generator, steps_per_epoch = nb_train_samples // batch_size, validation_data=validation_generator, validation_steps=nb_validation_samples // batch_size, epochs=400, verbose=1, callbacks=[csv_logger])\n    File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/tmp/ipykernel_20753/190348602.py\", line 17, in train_step\n      loss = self.compiled_loss(labels, predictions)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 1990, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/backend.py\", line 5534, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[16,3] labels_size=[16,101]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_109592]"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "K.clear_session()\n",
    "history = model.fit(train_generator, steps_per_epoch = nb_train_samples // batch_size, validation_data=validation_generator, validation_steps=nb_validation_samples // batch_size, epochs=400, verbose=1, callbacks=[csv_logger])\n",
    "# model.save('EfficientSAM.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3BpWcwjGqrr"
   },
   "outputs": [],
   "source": [
    "plot_Acc_and_Loss(history, \"EfficientNetV2S + SAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dP6dqgb9_Zaf"
   },
   "source": [
    "Try to reload the model, freeze the base model and then unfreeze the last layers of the model."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "s4DUFALj95De",
    "phIo8-jMHPdk",
    "EBwS-eRXS3EK",
    "D0piSCKpS_X_",
    "1XCSfslOlmEU",
    "hje0vk10fOwg",
    "PCqQorhmjpgO",
    "v6rXFmp3nokv"
   ],
   "name": "Food101_TestModels.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "45f8683c9252a88b8f420901eacb34fcdb5939f1b6daec3cbc0724dfb08907e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
