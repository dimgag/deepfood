{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNaVQGQ9tQRr"
   },
   "source": [
    "# **Multiclass Classification using Keras and TensorFlow on Food-101 Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oNJr8de7yp3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 09:59:00.952073: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-09 09:59:01.235013: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-08-09 09:59:02.029376: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-08-09 09:59:02.029490: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-08-09 09:59:02.029505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S, EfficientNetV2L\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Note, selecting 'libglu1-mesa' instead of 'libglu1'\n",
      "libglu1-mesa is already the newest version (9.0.1-1build1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 100 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# !apt-get update\n",
    "# !apt-get install ffmpeg libsm6 libxext6  -y\n",
    "!apt-get install libglu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "E: Unable to locate package libsm7\n",
      "E: Unable to locate package libxext7\n"
     ]
    }
   ],
   "source": [
    "# !apt-get update\n",
    "!apt-get install ffmpeg libsm7 libxext7  -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TEC_CRt_c_Z"
   },
   "source": [
    "### **Download the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JOZZbCDoP-Hy"
   },
   "outputs": [],
   "source": [
    "# # Check if GPU is enabled\n",
    "# print(tf.__version__)\n",
    "# print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "i4hckYW2yp3c"
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/input/food-101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "f88XvEBTQBS9"
   },
   "outputs": [],
   "source": [
    "# # Helper function to download data and extract\n",
    "# def get_data_extract():\n",
    "#   if \"food-101\" in os.listdir():\n",
    "#     print(\"Dataset already exists\")\n",
    "#   else:\n",
    "#     print(\"Downloading the data...\")\n",
    "#     !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
    "#     print(\"Dataset downloaded!\")\n",
    "#     print(\"Extracting data..\")\n",
    "#     !tar xzvf food-101.tar.gz\n",
    "#     print(\"Extraction done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O7kY0v23QJGO",
    "outputId": "c4afcace-bc05-4589-e314-c70f96806937"
   },
   "outputs": [],
   "source": [
    "# Download data and extract it to folder\n",
    "# Uncomment this below line if you are on Colab\n",
    "# get_data_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIgareCETmct"
   },
   "source": [
    "### **Split the image data into train and test using train.txt and test.txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xB0XMUX_5KMQ"
   },
   "outputs": [],
   "source": [
    "# # Helper method to split dataset into train and test folders\n",
    "# def prepare_data(filepath, src,dest):\n",
    "#   classes_images = defaultdict(list)\n",
    "#   with open(filepath, 'r') as txt:\n",
    "#       paths = [read.strip() for read in txt.readlines()]\n",
    "#       for p in paths:\n",
    "#         food = p.split('/')\n",
    "#         classes_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "#   for food in classes_images.keys():\n",
    "#     print(\"\\nCopying images into \",food)\n",
    "#     if not os.path.exists(os.path.join(dest,food)):\n",
    "#       os.makedirs(os.path.join(dest,food))\n",
    "#     for i in classes_images[food]:\n",
    "#       copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
    "#   print(\"Copying Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJyt1aH-DDfh",
    "outputId": "7f44b6c9-764a-47be-f53a-080c5ac173e1"
   },
   "outputs": [],
   "source": [
    "# %cd food-101/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSgcYcqy5KUd",
    "outputId": "2d3f475d-5dd7-42c6-95fe-7a4fd2fd3653"
   },
   "outputs": [],
   "source": [
    "# prepare_data('/content/food-101/meta/train.txt', '/content/food-101/images', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JI65wZgT5Kb-",
    "outputId": "d6164673-667f-4fad-a4f6-69bdadfdd1bb"
   },
   "outputs": [],
   "source": [
    "# prepare_data('/content/food-101/meta/test.txt', '/content/food-101/images', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xccc8PJP5K1G",
    "outputId": "2d5f8b05-daaf-4e0f-c974-decec71737d6"
   },
   "outputs": [],
   "source": [
    "# # Check how many files are in the train folder\n",
    "# print(\"Total number of samples in train folder\")\n",
    "# !find train -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iz3fjQw25K3-",
    "outputId": "21e1b0ac-72b1-407b-e69e-55239a249ac9"
   },
   "outputs": [],
   "source": [
    "# # Check how many files are in the test folder\n",
    "# print(\"Total number of samples in test folder\")\n",
    "# !find test -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5rLWIHpUGWf"
   },
   "source": [
    "### **Create a subset of data with few classes(3) - train_mini and test_mini for experimenting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tYyJGTJ6J9CP"
   },
   "outputs": [],
   "source": [
    "# # Helper method to create train_mini and test_mini data samples\n",
    "# def dataset_mini(food_list, src, dest):\n",
    "#   if os.path.exists(dest):\n",
    "#     rmtree(dest) # removing dataset_mini(if it already exists) folders so that we will have only the classes that we want\n",
    "#   os.makedirs(dest)\n",
    "#   for food_item in food_list :\n",
    "#     print(\"Copying images into\",food_item)\n",
    "#     copytree(os.path.join(src,food_item), os.path.join(dest,food_item))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9YAscZLV5LFK"
   },
   "outputs": [],
   "source": [
    "# # picking 3 food items and generating separate data folders for the same\n",
    "# food_list = ['apple_pie','pizza','omelette']\n",
    "# src_train = 'train'\n",
    "# dest_train = 'train_mini'\n",
    "# src_test = 'test'\n",
    "# dest_test = 'test_mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvlXbJ3NoPzy",
    "outputId": "164b2b38-9b6a-46aa-bea3-fa9cc79d039c"
   },
   "outputs": [],
   "source": [
    "# print(\"Creating train data folder with new classes\")\n",
    "# dataset_mini(food_list, src_train, dest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7mWJCev5LI8",
    "outputId": "0c034278-b1d7-4586-8e8b-cb5199e137ba"
   },
   "outputs": [],
   "source": [
    "# print(\"Total number of samples in train folder\")\n",
    "\n",
    "# !find train_mini -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4aeURey5LLy",
    "outputId": "70761a91-6917-4c6e-d6c0-f6264789904a"
   },
   "outputs": [],
   "source": [
    "# print(\"Creating test data folder with new classes\")\n",
    "# dataset_mini(food_list, src_test, dest_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LBLq_gYD5LOm",
    "outputId": "3fdb15d0-60b6-429b-873a-3b51827839e5"
   },
   "outputs": [],
   "source": [
    "# print(\"Total number of samples in test folder\")\n",
    "# !find test_mini -type d -or -type f -printf '.' | wc -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uBYnTC8I4mw"
   },
   "source": [
    "### **Data Augmentation and Acc/Loss Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/persistent\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/persistent\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/persistent/food-101\n"
     ]
    }
   ],
   "source": [
    "%cd food-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HC3eXlRJHMI7",
    "outputId": "5c45e504-956c-4f38-d79c-460138afdf3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75750 images belonging to 101 classes.\n",
      "Found 25250 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "# K.clear_session()\n",
    "n_classes = 101\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'test'\n",
    "# train_data_dir = '/Users/dim__gag/python/food-101/data_mini/train_mini'\n",
    "# validation_data_dir = '/Users/dim__gag/python/food-101/data_mini/test_mini'\n",
    "\n",
    "nb_train_samples = 75750\n",
    "nb_validation_samples = 25250\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EpyszTY3iyyI"
   },
   "outputs": [],
   "source": [
    "# Plot Accuracy and Loss of the model\n",
    "def plot_accuracy(history,title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
    "    plt.show()\n",
    "def plot_loss(history,title):\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_Acc_and_Loss(history,title):\n",
    "    # plot model accuracy\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
    "    # plot model loss\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(title)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hArz5ffBjtwm"
   },
   "source": [
    "## **EfficientNetV2S & SAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "zxc063O9powb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 09:59:11.256887: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-09 09:59:11.992389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30935 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# K.clear_session()\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S, EfficientNetV2L\n",
    "# base_EffNet = EfficientNetV2S(include_top=False, weights='imagenet')\n",
    "base_EffNet = EfficientNetV2L(include_top=False, weights='imagenet')\n",
    "\n",
    "base_EffNet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "kzsXXkvyvV9j"
   },
   "outputs": [],
   "source": [
    "# base_EffNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "PPkNXdtSvV7O"
   },
   "outputs": [],
   "source": [
    "# Fine tune the model\n",
    "x = base_EffNet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(101, kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "EffNet = Model(inputs=base_EffNet.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XDpUw9m8vV4s"
   },
   "outputs": [],
   "source": [
    "# EffNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "L1NcXkVUFSe5"
   },
   "outputs": [],
   "source": [
    "# <-------------------------------------------------------------------------------------------------------------->\n",
    "class SAMModel(tf.keras.Model):\n",
    "    def __init__(self, model, rho=0.05):\n",
    "        \"\"\"\n",
    "        p, q = 2 for optimal results as suggested in the paper\n",
    "        (Section 2)\n",
    "        \"\"\"\n",
    "        super(SAMModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.rho = rho\n",
    "\n",
    "    def train_step(self, data):\n",
    "        (images, labels) = data\n",
    "        e_ws = []\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.model(images)\n",
    "            loss = self.compiled_loss(labels, predictions)\n",
    "        trainable_params = self.model.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_params)\n",
    "        grad_norm = self._grad_norm(gradients)\n",
    "        scale = self.rho / (grad_norm + 1e-12)\n",
    "\n",
    "        for (grad, param) in zip(gradients, trainable_params):\n",
    "            e_w = grad * scale\n",
    "            param.assign_add(e_w)\n",
    "            e_ws.append(e_w)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.model(images)\n",
    "            loss = self.compiled_loss(labels, predictions)    \n",
    "        \n",
    "        sam_gradients = tape.gradient(loss, trainable_params)\n",
    "        for (param, e_w) in zip(trainable_params, e_ws):\n",
    "            param.assign_sub(e_w)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(sam_gradients, trainable_params))\n",
    "        \n",
    "        self.compiled_metrics.update_state(labels, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        (images, labels) = data\n",
    "        predictions = self.model(images, training=False)\n",
    "        loss = self.compiled_loss(labels, predictions)\n",
    "        self.compiled_metrics.update_state(labels, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def _grad_norm(self, gradients):\n",
    "        norm = tf.norm(\n",
    "            tf.stack([\n",
    "                tf.norm(grad) for grad in gradients if grad is not None\n",
    "            ])\n",
    "        )\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "h65CJmO43gRI"
   },
   "outputs": [],
   "source": [
    "model = SAMModel(EffNet)\n",
    "# model = EffNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "PDVyHLDuFXDK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 10:01:18.763824: I tensorflow/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 239s 1s/step - loss: 4.6361 - accuracy: 0.0022 - val_loss: 4.6159 - val_accuracy: 0.0068\n",
      "Epoch 2/100\n",
      "140/140 [==============================] - 130s 923ms/step - loss: 4.6307 - accuracy: 0.0013 - val_loss: 4.6159 - val_accuracy: 0.0149\n",
      "Epoch 3/100\n",
      "140/140 [==============================] - 126s 895ms/step - loss: 4.6262 - accuracy: 0.0000e+00 - val_loss: 4.6148 - val_accuracy: 0.0136\n",
      "Epoch 4/100\n",
      "140/140 [==============================] - 118s 836ms/step - loss: 4.6256 - accuracy: 0.0013 - val_loss: 4.6150 - val_accuracy: 0.0068\n",
      "Epoch 5/100\n",
      " 43/140 [========>.....................] - ETA: 1:03 - loss: 4.6241 - accuracy: 0.0015"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# checkpointer = ModelCheckpoint(filepath='EfficientSAM.hdf5', verbose=1, save_best_only=True)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m csv_logger \u001b[38;5;241m=\u001b[39m CSVLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEfficientSAM_1.log\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnb_train_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_validation_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:898\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    895\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 898\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    901\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:930\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    927\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 930\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    932\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    933\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    934\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2469\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2466\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2467\u001b[0m   (graph_function,\n\u001b[1;32m   2468\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1835\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1831\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1832\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1833\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1834\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1835\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1836\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1837\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1838\u001b[0m     args,\n\u001b[1;32m   1839\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1840\u001b[0m     executing_eagerly)\n\u001b[1;32m   1841\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py:480\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    489\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    493\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GET THE SAM MODEL\n",
    "model.trainable = True # Unfreeze the model\n",
    "model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# checkpointer = ModelCheckpoint(filepath='EfficientSAM.hdf5', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger('EfficientSAM_1.log')\n",
    "\n",
    "history = model.fit(train_generator, steps_per_epoch = nb_train_samples // batch_size, validation_data=validation_generator, validation_steps=nb_validation_samples // batch_size, epochs=100, verbose=1, callbacks=[csv_logger]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GPUs\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "# import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mirrored_strategy.scope():\n",
    "#     base_EffNet = EfficientNetV2L(include_top=False, weights='imagenet')\n",
    "#     base_EffNet.trainable = False    \n",
    "\n",
    "#     # Fine tune the model\n",
    "#     x = base_EffNet.output\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "#     x = Dense(128, activation='relu')(x)\n",
    "#     x = Dropout(0.2)(x)\n",
    "#     predictions = Dense(3, kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "#     EffNet = Model(inputs=base_EffNet.input, outputs=predictions)\n",
    "\n",
    "#     # INCLUDE SAM MODEL OPT\n",
    "#     model = SAMModel(EffNet)\n",
    "#     # model = EffNet # model without SAM optimizer\n",
    "\n",
    "#     # GET THE SAM MODEL\n",
    "#     model.trainable = True # Unfreeze the model\n",
    "#     model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     # checkpointer = ModelCheckpoint(filepath='EfficientSAM.hdf5', verbose=1, save_best_only=True)\n",
    "#     csv_logger = CSVLogger('EfficientSAM_1.log')\n",
    "\n",
    "#     history = model.fit(train_generator, steps_per_epoch = nb_train_samples // batch_size, validation_data=validation_generator, validation_steps=nb_validation_samples // batch_size, epochs=100, verbose=1, callbacks=[csv_logger]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3BpWcwjGqrr"
   },
   "outputs": [],
   "source": [
    "plot_Acc_and_Loss(history, \"EfficientNetV2S + SAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('EfficientSAM.hdf5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "s4DUFALj95De",
    "phIo8-jMHPdk",
    "EBwS-eRXS3EK",
    "D0piSCKpS_X_",
    "1XCSfslOlmEU",
    "hje0vk10fOwg",
    "PCqQorhmjpgO",
    "v6rXFmp3nokv"
   ],
   "name": "Food101_TestModels.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "45f8683c9252a88b8f420901eacb34fcdb5939f1b6daec3cbc0724dfb08907e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
