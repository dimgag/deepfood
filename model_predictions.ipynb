{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the best saved models to make predictions\n",
    "K.clear_session()\n",
    "# model_best = load_model('models/EfficientNetV2S/EfficientNetV2S.hdf5', compile=False)\n",
    "# model_best = load_model('models/EfficientNetV2L/EfficientNetV2L.hdf5', compile=False)\n",
    "model_best = load_model('/Users/dim__gag/Desktop/EfficientNetV2L/EfficientNetV2L.hdf5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Foods sorted\n",
    "# data_dir = \"/workspace/persistent/food-101/images\" # This is for DSRI workspace path\n",
    "\n",
    "data_dir = \"/Users/dim__gag/Desktop/food-101/images\" # This is for local path\n",
    "\n",
    "foods_sorted = sorted(os.listdir(data_dir))\n",
    "\n",
    "\n",
    "# foods_sorted = ['apple_pie','pizza','omelette']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(foods_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_n_random_classes(n):\n",
    "  food_list = []\n",
    "  random_food_indices = random.sample(range(len(foods_sorted)),n) # We are picking n random food classes\n",
    "  for i in random_food_indices:\n",
    "    food_list.append(foods_sorted[i])\n",
    "  food_list.sort()\n",
    "  return food_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_list = pick_n_random_classes(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model, images, show = True):\n",
    "  for img in images:\n",
    "    img = image.load_img(img, target_size=(299, 299))\n",
    "    img = image.img_to_array(img)                    \n",
    "    img = np.expand_dims(img, axis=0)         \n",
    "    img /= 255.                                      \n",
    "\n",
    "    pred = model.predict(img)\n",
    "    index = np.argmax(pred)\n",
    "    food_list.sort()\n",
    "    pred_value = food_list[index]\n",
    "    if show:\n",
    "        plt.imshow(img[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.title(pred_value) \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [] \n",
    "# images.append('test_images/Apple.jpg')\n",
    "# images.append('test_images/applepie.jpg')\n",
    "# images.append('test_images/cupcakes.jpg')\n",
    "# images.append('test_images/springrolls.jpg')\n",
    "# images.append('test_images/samosa.jpg')\n",
    "\n",
    "\n",
    "# images.append('test_images/burger.jpeg')\n",
    "# images.append('test_images/hardburger.jpg')\n",
    "# images.append('test_images/dim1.jpeg')\n",
    "# images.append('test_images/dim2.jpeg')\n",
    "\n",
    "# images.append('test_images/leo.jpg')\n",
    "\n",
    "\n",
    "images.append('test_images/steak.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show images\n",
    "predict_class(model_best, images, show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = []\n",
    "wrong.append('test_images/hardburger.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_class(model_best, wrong, show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Details and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EfficientNetV2S = load_model('models/EfficientNetV2S/EfficientNetV2S.hdf5')\n",
    "\n",
    "EfficientNetV2L = load_model('models/EfficientNetV2L/EfficientNetV2L.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_details(model):\n",
    "    def namestr(obj, namespace):\n",
    "        return [name for name in namespace if namespace[name] is obj]\n",
    "    print(\"==========================================================\")            \n",
    "    print(\"Model Name: \", namestr(model, globals()))\n",
    "    print(\"Number of Layers: \", len(model.layers))\n",
    "    print(\"Number of Parameters: \", format(model.count_params(), ',d'))\n",
    "    print(\"==========================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_details(EfficientNetV2S)\n",
    "print_model_details(EfficientNetV2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from collections import defaultdict\n",
    "import collections\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Train Data\n",
    "classes_images=defaultdict(list)\n",
    "with open('/Users/dim__gag/Desktop/food-101/meta/train.txt', 'r') as txt:\n",
    "\tpaths= [read.strip() for read in txt.readlines()]\n",
    "\tfor p in paths:\n",
    "\t\tfood = p.split('/')\n",
    "\t\tclasses_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "for food in classes_images.keys():\n",
    "\tif not os.path.exists(os.path.join(\"/Users/dim__gag/Desktop/food-101/train\",food)):\n",
    "\t\tos.makedirs(os.path.join(\"/Users/dim__gag/Desktop/food-101/train\", food))\n",
    "\tfor i in classes_images[food]:\n",
    "\t\tshutil.copyfile(os.path.join(\"/Users/dim__gag/Desktop/food-101/images\", food, i), os.path.join(\"/Users/dim__gag/Desktop/food-101/train\", food, i))\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Test/Validation Data\n",
    "classes_images=defaultdict(list)\n",
    "with open('/Users/dim__gag/Desktop/food-101/meta/test.txt', 'r') as txt:\n",
    "\tpaths= [read.strip() for read in txt.readlines()]\n",
    "\tfor p in paths:\n",
    "\t\tfood = p.split('/')\n",
    "\t\tclasses_images[food[0]].append(food[1] + '.jpg')\n",
    "\n",
    "for food in classes_images.keys():\n",
    "\tif not os.path.exists(os.path.join(\"/Users/dim__gag/Desktop/food-101/test\",food)):\n",
    "\t\tos.makedirs(os.path.join(\"/Users/dim__gag/Desktop/food-101/test\", food))\n",
    "\tfor i in classes_images[food]:\n",
    "\t\tshutil.copyfile(os.path.join(\"/Users/dim__gag/Desktop/food-101/images\", food, i), os.path.join(\"/Users/dim__gag/Desktop/food-101/test\", food, i))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/dim__gag/Desktop/food-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation for Evaluation\n",
    "train_data_dir = \"/Users/dim__gag/Desktop/food-101/train\"\n",
    "validation_data_dir = \"/Users/dim__gag/Desktop/food-101/test\"\n",
    "img_width, img_height = 299, 299 # input image dimensions\n",
    "batch_size = 32 # Change this to your desired batch size\n",
    "# epochs = 100 # Change the Number of epochs here\n",
    "\n",
    "def data_augmentation(train_data_dir, validation_data_dir, img_height, img_width, batch_size):\n",
    "    # Data Augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    return train_generator, validation_generator\n",
    "\n",
    "\n",
    "\n",
    "train_generator, validation_generator = data_augmentation(train_data_dir=train_data_dir, validation_data_dir=validation_data_dir, img_width=img_height, img_height=img_height, batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print training, test accuracy and loss of the model\n",
    "def model_eval(model, train, val):\n",
    "    # evaluate the model\n",
    "    train_loss, train_acc = model.evaluate(train, verbose=0)\n",
    "    val_loss, val_acc = model.evaluate(val, verbose=0)\n",
    "    print('Train loss:', train_loss)\n",
    "    print('Train accuracy:', train_acc)\n",
    "    print('Validation loss:', val_loss)\n",
    "    print('Validation accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(EfficientNetV2S, train_generator, validation_generator)\n",
    "model_eval(EfficientNetV2L, train_generator, validation_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "45f8683c9252a88b8f420901eacb34fcdb5939f1b6daec3cbc0724dfb08907e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
